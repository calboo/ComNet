{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb786f7d",
   "metadata": {},
   "source": [
    "# Main Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1c41c6-b973-4da2-bebe-ba1c3f49fd58",
   "metadata": {},
   "source": [
    "### Naive model statistics for baseline GLD 1 day\n",
    "\n",
    "The average probability density is:  0.279  \n",
    "The average NLL is:  0.485  \n",
    "The average MAE is:  0.665  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d858ef24-4fb9-41fe-a055-2daadfe10e94",
   "metadata": {},
   "source": [
    "### Train/Eval Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f8f5d9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple MPS Framework for GPU acceleration with 1 local device/s \n",
      "\n",
      "Model initialised with 0.0329 million parameters occupying 1054.45 MB \n",
      "\n",
      "Training begins... \n",
      "\n",
      "| Epoch   1 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.04 | loss 4.74896957 |\n",
      "| Epoch   1 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  6.74 | loss 2.41155440 |\n",
      "| Epoch   1 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.83 | loss 2.23673775 |\n",
      "| Epoch   1 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.99 | loss 2.25490082 |\n",
      "| Epoch   1 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  8.46 | loss 2.30939329 |\n",
      "| Epoch   1 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  7.80 | loss 2.14450026 |\n",
      "| Epoch   1 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.79 | loss 2.17618304 |\n",
      "| Epoch   2 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.94 | loss 2.05272086 |\n",
      "| Epoch   2 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.77 | loss 2.26119392 |\n",
      "| Epoch   2 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.98 | loss 2.15011828 |\n",
      "| Epoch   2 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.66 | loss 2.15709567 |\n",
      "| Epoch   2 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.08 | loss 2.14011815 |\n",
      "| Epoch   2 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  7.98 | loss 2.15070118 |\n",
      "| Epoch   2 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.97 | loss 2.08794712 |\n",
      "| Epoch   3 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.75 | loss 2.13484441 |\n",
      "| Epoch   3 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.57 | loss 2.14783873 |\n",
      "| Epoch   3 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.13 | loss 2.06617752 |\n",
      "| Epoch   3 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.18 | loss 2.18914944 |\n",
      "| Epoch   3 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.15 | loss 2.09523887 |\n",
      "| Epoch   3 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  7.33 | loss 2.13358769 |\n",
      "| Epoch   3 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.43 | loss 2.15362820 |\n",
      "| Epoch   4 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  6.95 | loss 2.09497839 |\n",
      "| Epoch   4 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.65 | loss 2.12335165 |\n",
      "| Epoch   4 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.39 | loss 2.16117269 |\n",
      "| Epoch   4 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.76 | loss 2.10398156 |\n",
      "| Epoch   4 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.91 | loss 2.13544207 |\n",
      "| Epoch   4 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.38 | loss 2.07468414 |\n",
      "| Epoch   4 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.25 | loss 2.19217888 |\n",
      "| Epoch   5 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  8.24 | loss 2.13820728 |\n",
      "| Epoch   5 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  8.23 | loss 2.14619936 |\n",
      "| Epoch   5 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.51 | loss 2.09919884 |\n",
      "| Epoch   5 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  6.80 | loss 2.12372291 |\n",
      "| Epoch   5 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.57 | loss 2.13067168 |\n",
      "| Epoch   5 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  7.37 | loss 2.13544911 |\n",
      "| Epoch   5 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.09 | loss 2.10899906 |\n",
      "\n",
      " Test statistics \n",
      "\n",
      "| Average Loss 1.86026 | Average Probability Density 0.06650 | Average MAE on mean 2.64069 |\n",
      "| Average mean 0.86503 | Average absolute value of mean 0.86503 | Average variance 25.94722 |\n",
      "\n",
      "| Singular Loss 1.86822 | Singular Probability Density 0.06575 | Singular MAE on mean 2.67756 |\n",
      "\n",
      "Model saved to path: outputs/TESTING/Future_Forecast/GLD_20_day_1/Future_Forecast.pkl\n",
      "\n",
      "| Epoch   6 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.12 | loss 2.12728369 |\n",
      "| Epoch   6 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.92 | loss 2.16575157 |\n",
      "| Epoch   6 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.30 | loss 2.07845546 |\n",
      "| Epoch   6 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.27 | loss 2.10499371 |\n",
      "| Epoch   6 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.69 | loss 2.11030979 |\n",
      "| Epoch   6 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  7.44 | loss 2.12019659 |\n",
      "| Epoch   6 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.12 | loss 2.12112153 |\n",
      "| Epoch   7 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  8.01 | loss 2.14305867 |\n",
      "| Epoch   7 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.60 | loss 2.14905676 |\n",
      "| Epoch   7 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.04 | loss 2.07111442 |\n",
      "| Epoch   7 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.26 | loss 2.11669213 |\n",
      "| Epoch   7 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.72 | loss 2.12649146 |\n",
      "| Epoch   7 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  7.57 | loss 2.08728311 |\n",
      "| Epoch   7 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.77 | loss 2.14764047 |\n",
      "| Epoch   8 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.63 | loss 2.07596309 |\n",
      "| Epoch   8 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.52 | loss 2.15357297 |\n",
      "| Epoch   8 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.35 | loss 2.13106192 |\n",
      "| Epoch   8 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.76 | loss 2.10714733 |\n",
      "| Epoch   8 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.75 | loss 2.14741094 |\n",
      "| Epoch   8 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  7.71 | loss 2.10950799 |\n",
      "| Epoch   8 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.07 | loss 2.10751961 |\n",
      "| Epoch   9 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.88 | loss 2.14348351 |\n",
      "| Epoch   9 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  8.15 | loss 2.16658490 |\n",
      "| Epoch   9 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.16 | loss 2.13145338 |\n",
      "| Epoch   9 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.61 | loss 2.10231838 |\n",
      "| Epoch   9 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.96 | loss 2.09875092 |\n",
      "| Epoch   9 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.29 | loss 2.03356746 |\n",
      "| Epoch   9 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.88 | loss 2.14408983 |\n",
      "| Epoch  10 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.96 | loss 2.17285043 |\n",
      "| Epoch  10 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  8.14 | loss 2.10927249 |\n",
      "| Epoch  10 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.69 | loss 2.09419412 |\n",
      "| Epoch  10 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.97 | loss 2.14856527 |\n",
      "| Epoch  10 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  8.65 | loss 2.07036130 |\n",
      "| Epoch  10 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.34 | loss 2.10274246 |\n",
      "| Epoch  10 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.53 | loss 2.09743232 |\n",
      "\n",
      " Test statistics \n",
      "\n",
      "| Average Loss 1.85463 | Average Probability Density 0.06720 | Average MAE on mean 2.62404 |\n",
      "| Average mean 0.76832 | Average absolute value of mean 0.76832 | Average variance 25.42531 |\n",
      "\n",
      "| Singular Loss 1.86335 | Singular Probability Density 0.06630 | Singular MAE on mean 2.66586 |\n",
      "\n",
      "Model saved to path: outputs/TESTING/Future_Forecast/GLD_20_day_1/Future_Forecast.pkl\n",
      "\n",
      "| Epoch  11 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  6.70 | loss 2.09605977 |\n",
      "| Epoch  11 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  8.17 | loss 2.09964192 |\n",
      "| Epoch  11 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.00 | loss 2.13915980 |\n",
      "| Epoch  11 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.57 | loss 2.08970079 |\n",
      "| Epoch  11 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  8.58 | loss 2.14170494 |\n",
      "| Epoch  11 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.21 | loss 2.08637400 |\n",
      "| Epoch  11 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.64 | loss 2.11214365 |\n",
      "| Epoch  12 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  8.19 | loss 2.16824177 |\n",
      "| Epoch  12 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  8.66 | loss 2.09916598 |\n",
      "| Epoch  12 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.17 | loss 2.11654524 |\n",
      "| Epoch  12 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.29 | loss 2.04184362 |\n",
      "| Epoch  12 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  8.57 | loss 2.10257432 |\n",
      "| Epoch  12 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.12 | loss 2.12882786 |\n",
      "| Epoch  12 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.46 | loss 2.12278571 |\n",
      "| Epoch  13 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.96 | loss 2.15344663 |\n",
      "| Epoch  13 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  8.08 | loss 2.07080629 |\n",
      "| Epoch  13 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.31 | loss 2.10611615 |\n",
      "| Epoch  13 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.11 | loss 2.08660107 |\n",
      "| Epoch  13 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.54 | loss 2.12426590 |\n",
      "| Epoch  13 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.31 | loss 2.09804856 |\n",
      "| Epoch  13 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.97 | loss 2.11274580 |\n",
      "| Epoch  14 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.81 | loss 2.10715382 |\n",
      "| Epoch  14 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  8.11 | loss 2.06514130 |\n",
      "| Epoch  14 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.21 | loss 2.13075510 |\n",
      "| Epoch  14 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.30 | loss 2.12097253 |\n",
      "| Epoch  14 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  8.31 | loss 2.13502749 |\n",
      "| Epoch  14 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  7.94 | loss 2.08269036 |\n",
      "| Epoch  14 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.36 | loss 2.11088528 |\n",
      "| Epoch  15 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  8.11 | loss 2.09953307 |\n",
      "| Epoch  15 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  8.21 | loss 2.08630327 |\n",
      "| Epoch  15 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.33 | loss 2.15383013 |\n",
      "| Epoch  15 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.63 | loss 2.14380023 |\n",
      "| Epoch  15 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  8.35 | loss 2.06783615 |\n",
      "| Epoch  15 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.21 | loss 2.05734335 |\n",
      "| Epoch  15 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.04 | loss 2.12059070 |\n",
      "\n",
      " Test statistics \n",
      "\n",
      "| Average Loss 1.84503 | Average Probability Density 0.06820 | Average MAE on mean 2.62059 |\n",
      "| Average mean 0.89319 | Average absolute value of mean 0.89319 | Average variance 24.63864 |\n",
      "\n",
      "| Singular Loss 1.85507 | Singular Probability Density 0.06697 | Singular MAE on mean 2.68148 |\n",
      "\n",
      "Model saved to path: outputs/TESTING/Future_Forecast/GLD_20_day_1/Future_Forecast.pkl\n",
      "\n",
      "| Epoch  16 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.58 | loss 2.15535985 |\n",
      "| Epoch  16 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.66 | loss 2.12137607 |\n",
      "| Epoch  16 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.81 | loss 2.08405078 |\n",
      "| Epoch  16 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.66 | loss 2.13067302 |\n",
      "| Epoch  16 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.68 | loss 2.08805256 |\n",
      "| Epoch  16 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  7.41 | loss 2.05389347 |\n",
      "| Epoch  16 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.02 | loss 2.03374161 |\n",
      "| Epoch  17 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.89 | loss 2.18469321 |\n",
      "| Epoch  17 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  8.19 | loss 2.05543037 |\n",
      "| Epoch  17 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.59 | loss 2.03238909 |\n",
      "| Epoch  17 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.06 | loss 2.07927874 |\n",
      "| Epoch  17 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  8.39 | loss 2.11958367 |\n",
      "| Epoch  17 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.09 | loss 2.12335770 |\n",
      "| Epoch  17 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.91 | loss 2.09918904 |\n",
      "| Epoch  18 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.89 | loss 2.12564847 |\n",
      "| Epoch  18 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.97 | loss 2.14379122 |\n",
      "| Epoch  18 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.81 | loss 2.05616596 |\n",
      "| Epoch  18 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.79 | loss 2.09672416 |\n",
      "| Epoch  18 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.77 | loss 2.04678983 |\n",
      "| Epoch  18 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.14 | loss 2.09847590 |\n",
      "| Epoch  18 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.04 | loss 2.14489015 |\n",
      "| Epoch  19 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  8.33 | loss 2.04909450 |\n",
      "| Epoch  19 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  8.21 | loss 2.12894449 |\n",
      "| Epoch  19 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.09 | loss 2.07472499 |\n",
      "| Epoch  19 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.95 | loss 2.09690718 |\n",
      "| Epoch  19 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  8.31 | loss 2.06125750 |\n",
      "| Epoch  19 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.05 | loss 2.15249056 |\n",
      "| Epoch  19 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.88 | loss 2.14364385 |\n",
      "| Epoch  20 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.66 | loss 2.14500209 |\n",
      "| Epoch  20 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.53 | loss 2.11499855 |\n",
      "| Epoch  20 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.57 | loss 2.07704305 |\n",
      "| Epoch  20 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.43 | loss 2.04959344 |\n",
      "| Epoch  20 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.55 | loss 2.14006910 |\n",
      "| Epoch  20 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.11 | loss 2.06243281 |\n",
      "| Epoch  20 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.02 | loss 2.11382533 |\n",
      "\n",
      " Test statistics \n",
      "\n",
      "| Average Loss 1.83380 | Average Probability Density 0.06951 | Average MAE on mean 2.62292 |\n",
      "| Average mean 0.92950 | Average absolute value of mean 0.92950 | Average variance 23.50449 |\n",
      "\n",
      "| Singular Loss 1.84372 | Singular Probability Density 0.06806 | Singular MAE on mean 2.68670 |\n",
      "\n",
      "Model saved to path: outputs/TESTING/Future_Forecast/GLD_20_day_1/Future_Forecast.pkl\n",
      "\n",
      "| Epoch  21 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.60 | loss 2.14847234 |\n",
      "| Epoch  21 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  8.52 | loss 2.13059539 |\n",
      "| Epoch  21 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.41 | loss 2.11636947 |\n",
      "| Epoch  21 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.02 | loss 2.04188226 |\n",
      "| Epoch  21 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  8.26 | loss 2.05105830 |\n",
      "| Epoch  21 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.32 | loss 2.03480436 |\n",
      "| Epoch  21 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.40 | loss 2.14601796 |\n",
      "| Epoch  22 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.74 | loss 2.07264156 |\n",
      "| Epoch  22 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.63 | loss 2.04822287 |\n",
      "| Epoch  22 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.72 | loss 2.10886820 |\n",
      "| Epoch  22 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.23 | loss 2.09048378 |\n",
      "| Epoch  22 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.36 | loss 2.14513049 |\n",
      "| Epoch  22 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  7.96 | loss 2.07488226 |\n",
      "| Epoch  22 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.66 | loss 2.10309435 |\n",
      "| Epoch  23 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.78 | loss 2.09269124 |\n",
      "| Epoch  23 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.75 | loss 2.10374255 |\n",
      "| Epoch  23 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.78 | loss 2.09608290 |\n",
      "| Epoch  23 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.57 | loss 2.19016158 |\n",
      "| Epoch  23 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.43 | loss 2.03853689 |\n",
      "| Epoch  23 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.09 | loss 2.05524293 |\n",
      "| Epoch  23 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.58 | loss 2.05190767 |\n",
      "| Epoch  24 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.75 | loss 2.14813494 |\n",
      "| Epoch  24 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.62 | loss 2.08717226 |\n",
      "| Epoch  24 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.95 | loss 2.03782991 |\n",
      "| Epoch  24 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.52 | loss 2.11373639 |\n",
      "| Epoch  24 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.82 | loss 2.06940012 |\n",
      "| Epoch  24 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.47 | loss 2.10659687 |\n",
      "| Epoch  24 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.55 | loss 2.06910262 |\n",
      "| Epoch  25 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.97 | loss 2.11005493 |\n",
      "| Epoch  25 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.97 | loss 2.06943114 |\n",
      "| Epoch  25 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.20 | loss 2.08829470 |\n",
      "| Epoch  25 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.86 | loss 2.07927975 |\n",
      "| Epoch  25 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.80 | loss 2.11087181 |\n",
      "| Epoch  25 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.10 | loss 2.05781185 |\n",
      "| Epoch  25 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.81 | loss 2.12650235 |\n",
      "\n",
      " Test statistics \n",
      "\n",
      "| Average Loss 1.83325 | Average Probability Density 0.07028 | Average MAE on mean 2.61273 |\n",
      "| Average mean 0.67185 | Average absolute value of mean 0.67546 | Average variance 23.21076 |\n",
      "\n",
      "| Singular Loss 1.84199 | Singular Probability Density 0.06855 | Singular MAE on mean 2.65608 |\n",
      "\n",
      "Model saved to path: outputs/TESTING/Future_Forecast/GLD_20_day_1/Future_Forecast.pkl\n",
      "\n",
      "| Epoch  26 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.43 | loss 2.05475807 |\n",
      "| Epoch  26 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.98 | loss 2.05938264 |\n",
      "| Epoch  26 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.21 | loss 2.13067274 |\n",
      "| Epoch  26 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.03 | loss 2.09333395 |\n",
      "| Epoch  26 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.44 | loss 2.10043543 |\n",
      "| Epoch  26 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.06 | loss 2.06250998 |\n",
      "| Epoch  26 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.77 | loss 2.10984269 |\n",
      "| Epoch  27 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  6.83 | loss 2.07970962 |\n",
      "| Epoch  27 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  8.39 | loss 2.00408933 |\n",
      "| Epoch  27 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.62 | loss 2.04957375 |\n",
      "| Epoch  27 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.42 | loss 2.11844676 |\n",
      "| Epoch  27 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.76 | loss 2.12502708 |\n",
      "| Epoch  27 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  7.73 | loss 2.10408683 |\n",
      "| Epoch  27 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.56 | loss 2.10552236 |\n",
      "| Epoch  28 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.59 | loss 2.05927215 |\n",
      "| Epoch  28 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.57 | loss 2.07755226 |\n",
      "| Epoch  28 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.08 | loss 2.13037755 |\n",
      "| Epoch  28 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.83 | loss 2.10541556 |\n",
      "| Epoch  28 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.91 | loss 2.11105055 |\n",
      "| Epoch  28 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  7.68 | loss 2.01492443 |\n",
      "| Epoch  28 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.14 | loss 2.07670010 |\n",
      "| Epoch  29 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.52 | loss 2.09531969 |\n",
      "| Epoch  29 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.98 | loss 2.07041449 |\n",
      "| Epoch  29 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.97 | loss 2.07565184 |\n",
      "| Epoch  29 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.82 | loss 2.11551700 |\n",
      "| Epoch  29 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.80 | loss 2.10071339 |\n",
      "| Epoch  29 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  7.81 | loss 2.09269657 |\n",
      "| Epoch  29 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.29 | loss 2.00106301 |\n",
      "| Epoch  30 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  8.60 | loss 2.08080860 |\n",
      "| Epoch  30 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  8.02 | loss 2.13069245 |\n",
      "| Epoch  30 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.82 | loss 2.05264289 |\n",
      "| Epoch  30 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.13 | loss 2.09839031 |\n",
      "| Epoch  30 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.96 | loss 2.05012893 |\n",
      "| Epoch  30 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  7.70 | loss 2.03406519 |\n",
      "| Epoch  30 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.94 | loss 2.11806105 |\n",
      "\n",
      " Test statistics \n",
      "\n",
      "| Average Loss 1.82199 | Average Probability Density 0.07166 | Average MAE on mean 2.63888 |\n",
      "| Average mean 0.83221 | Average absolute value of mean 0.84586 | Average variance 21.97905 |\n",
      "\n",
      "| Singular Loss 1.82869 | Singular Probability Density 0.06977 | Singular MAE on mean 2.67327 |\n",
      "\n",
      "Model saved to path: outputs/TESTING/Future_Forecast/GLD_20_day_1/Future_Forecast.pkl\n",
      "\n",
      "| Epoch  31 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.55 | loss 2.08060814 |\n",
      "| Epoch  31 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  8.88 | loss 2.08222043 |\n",
      "| Epoch  31 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.46 | loss 2.08423997 |\n",
      "| Epoch  31 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.04 | loss 2.02891188 |\n",
      "| Epoch  31 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  8.29 | loss 2.08298252 |\n",
      "| Epoch  31 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.28 | loss 2.08846982 |\n",
      "| Epoch  31 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.18 | loss 2.08100322 |\n",
      "| Epoch  32 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.64 | loss 2.06263345 |\n",
      "| Epoch  32 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  8.66 | loss 2.06511758 |\n",
      "| Epoch  32 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.06 | loss 2.11309407 |\n",
      "| Epoch  32 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.00 | loss 2.06081179 |\n",
      "| Epoch  32 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  8.20 | loss 2.06177299 |\n",
      "| Epoch  32 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  7.40 | loss 2.15128959 |\n",
      "| Epoch  32 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.49 | loss 2.01336345 |\n",
      "| Epoch  33 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  8.17 | loss 2.05903664 |\n",
      "| Epoch  33 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.61 | loss 2.06821130 |\n",
      "| Epoch  33 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.65 | loss 2.10553192 |\n",
      "| Epoch  33 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.03 | loss 2.02988465 |\n",
      "| Epoch  33 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  8.04 | loss 2.08068024 |\n",
      "| Epoch  33 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.08 | loss 2.06731575 |\n",
      "| Epoch  33 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.11 | loss 2.09818154 |\n",
      "| Epoch  34 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.82 | loss 2.13058639 |\n",
      "| Epoch  34 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  8.44 | loss 2.05199768 |\n",
      "| Epoch  34 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.12 | loss 2.09126561 |\n",
      "| Epoch  34 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.16 | loss 2.03507654 |\n",
      "| Epoch  34 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.97 | loss 2.08508214 |\n",
      "| Epoch  34 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.71 | loss 2.06272285 |\n",
      "| Epoch  34 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.93 | loss 2.03817724 |\n",
      "| Epoch  35 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  8.09 | loss 2.06343825 |\n",
      "| Epoch  35 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.77 | loss 2.05966120 |\n",
      "| Epoch  35 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.85 | loss 2.12408093 |\n",
      "| Epoch  35 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.28 | loss 2.10771925 |\n",
      "| Epoch  35 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.98 | loss 2.10494236 |\n",
      "| Epoch  35 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  7.91 | loss 1.98358448 |\n",
      "| Epoch  35 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.19 | loss 2.06049721 |\n",
      "\n",
      " Test statistics \n",
      "\n",
      "| Average Loss 1.82217 | Average Probability Density 0.07283 | Average MAE on mean 2.69843 |\n",
      "| Average mean 0.65761 | Average absolute value of mean 0.73838 | Average variance 21.06713 |\n",
      "\n",
      "| Singular Loss 1.82114 | Singular Probability Density 0.07092 | Singular MAE on mean 2.65483 |\n",
      "\n",
      "Model saved to path: outputs/TESTING/Future_Forecast/GLD_20_day_1/Future_Forecast.pkl\n",
      "\n",
      "| Epoch  36 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.04 | loss 2.08701640 |\n",
      "| Epoch  36 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.84 | loss 2.05644397 |\n",
      "| Epoch  36 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.95 | loss 2.08539624 |\n",
      "| Epoch  36 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.59 | loss 2.04950928 |\n",
      "| Epoch  36 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  8.21 | loss 2.07956657 |\n",
      "| Epoch  36 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.26 | loss 2.07697618 |\n",
      "| Epoch  36 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.84 | loss 2.03073664 |\n",
      "| Epoch  37 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.22 | loss 2.11829960 |\n",
      "| Epoch  37 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.96 | loss 2.01198468 |\n",
      "| Epoch  37 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.53 | loss 2.08463216 |\n",
      "| Epoch  37 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.76 | loss 1.95110231 |\n",
      "| Epoch  37 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  8.07 | loss 2.09508078 |\n",
      "| Epoch  37 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.11 | loss 2.08087467 |\n",
      "| Epoch  37 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.00 | loss 2.11504592 |\n",
      "| Epoch  38 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  8.26 | loss 2.03089913 |\n",
      "| Epoch  38 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.80 | loss 2.10563407 |\n",
      "| Epoch  38 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.64 | loss 2.09271838 |\n",
      "| Epoch  38 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.45 | loss 2.06963046 |\n",
      "| Epoch  38 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.83 | loss 2.01297295 |\n",
      "| Epoch  38 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.06 | loss 2.01534123 |\n",
      "| Epoch  38 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.74 | loss 2.10993175 |\n",
      "| Epoch  39 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.62 | loss 2.02816227 |\n",
      "| Epoch  39 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  8.09 | loss 2.06552893 |\n",
      "| Epoch  39 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.71 | loss 2.03865460 |\n",
      "| Epoch  39 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.82 | loss 2.04820458 |\n",
      "| Epoch  39 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.75 | loss 2.13201607 |\n",
      "| Epoch  39 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  7.55 | loss 2.04951787 |\n",
      "| Epoch  39 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.03 | loss 2.07057717 |\n",
      "| Epoch  40 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  8.15 | loss 2.02351904 |\n",
      "| Epoch  40 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  8.21 | loss 2.01659592 |\n",
      "| Epoch  40 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.25 | loss 2.08940603 |\n",
      "| Epoch  40 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.13 | loss 2.07941071 |\n",
      "| Epoch  40 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  8.20 | loss 2.06072660 |\n",
      "| Epoch  40 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.42 | loss 2.01619045 |\n",
      "| Epoch  40 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.54 | loss 2.11232055 |\n",
      "\n",
      " Test statistics \n",
      "\n",
      "| Average Loss 1.84132 | Average Probability Density 0.07223 | Average MAE on mean 2.83240 |\n",
      "| Average mean 0.71050 | Average absolute value of mean 0.90046 | Average variance 21.61759 |\n",
      "\n",
      "| Singular Loss 1.82592 | Singular Probability Density 0.07026 | Singular MAE on mean 2.65983 |\n",
      "\n",
      "Model saved to path: outputs/TESTING/Future_Forecast/GLD_20_day_1/Future_Forecast.pkl\n",
      "\n",
      "| Epoch  41 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  6.72 | loss 2.06363245 |\n",
      "| Epoch  41 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  8.30 | loss 2.04561372 |\n",
      "| Epoch  41 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.58 | loss 2.04076883 |\n",
      "| Epoch  41 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.26 | loss 2.07433863 |\n",
      "| Epoch  41 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  8.75 | loss 2.05542038 |\n",
      "| Epoch  41 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.05 | loss 2.04671630 |\n",
      "| Epoch  41 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.76 | loss 2.05301360 |\n",
      "| Epoch  42 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.35 | loss 2.02779023 |\n",
      "| Epoch  42 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.84 | loss 2.10091350 |\n",
      "| Epoch  42 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.52 | loss 2.00504509 |\n",
      "| Epoch  42 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.69 | loss 2.03446051 |\n",
      "| Epoch  42 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.75 | loss 2.04140935 |\n",
      "| Epoch  42 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  7.74 | loss 2.08009338 |\n",
      "| Epoch  42 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.18 | loss 2.08742458 |\n",
      "| Epoch  43 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.73 | loss 2.08490403 |\n",
      "| Epoch  43 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.94 | loss 2.08088439 |\n",
      "| Epoch  43 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.84 | loss 2.01562211 |\n",
      "| Epoch  43 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.07 | loss 2.06378748 |\n",
      "| Epoch  43 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.74 | loss 2.02629291 |\n",
      "| Epoch  43 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.54 | loss 2.02421542 |\n",
      "| Epoch  43 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.14 | loss 1.99802949 |\n",
      "| Epoch  44 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.98 | loss 2.00424337 |\n",
      "| Epoch  44 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  8.32 | loss 2.08339453 |\n",
      "| Epoch  44 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.00 | loss 2.05528678 |\n",
      "| Epoch  44 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.74 | loss 2.09166821 |\n",
      "| Epoch  44 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.76 | loss 2.04892592 |\n",
      "| Epoch  44 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.29 | loss 1.97548952 |\n",
      "| Epoch  44 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.40 | loss 2.04274658 |\n",
      "| Epoch  45 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  8.16 | loss 1.98832650 |\n",
      "| Epoch  45 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.78 | loss 2.11423050 |\n",
      "| Epoch  45 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.52 | loss 2.01758961 |\n",
      "| Epoch  45 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.70 | loss 2.00293201 |\n",
      "| Epoch  45 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  8.03 | loss 2.02601442 |\n",
      "| Epoch  45 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  7.88 | loss 2.06529099 |\n",
      "| Epoch  45 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.21 | loss 2.07803718 |\n",
      "\n",
      " Test statistics \n",
      "\n",
      "| Average Loss 1.87821 | Average Probability Density 0.07176 | Average MAE on mean 3.05948 |\n",
      "| Average mean 0.33923 | Average absolute value of mean 0.91836 | Average variance 21.85229 |\n",
      "\n",
      "| Singular Loss 1.83474 | Singular Probability Density 0.07006 | Singular MAE on mean 2.63961 |\n",
      "\n",
      "Model saved to path: outputs/TESTING/Future_Forecast/GLD_20_day_1/Future_Forecast.pkl\n",
      "\n",
      "| Epoch  46 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.30 | loss 2.08268813 |\n",
      "| Epoch  46 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  8.39 | loss 1.97715396 |\n",
      "| Epoch  46 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.93 | loss 2.04730501 |\n",
      "| Epoch  46 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.16 | loss 2.04034815 |\n",
      "| Epoch  46 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  8.27 | loss 2.07308019 |\n",
      "| Epoch  46 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  7.57 | loss 1.98751461 |\n",
      "| Epoch  46 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.55 | loss 1.99025226 |\n",
      "| Epoch  47 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.62 | loss 2.05461258 |\n",
      "| Epoch  47 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.72 | loss 2.06591890 |\n",
      "| Epoch  47 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.86 | loss 2.02777497 |\n",
      "| Epoch  47 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.13 | loss 2.02498615 |\n",
      "| Epoch  47 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  8.15 | loss 2.04503311 |\n",
      "| Epoch  47 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  7.50 | loss 1.97547963 |\n",
      "| Epoch  47 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.30 | loss 2.05053330 |\n",
      "| Epoch  48 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  7.40 | loss 2.06647597 |\n",
      "| Epoch  48 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.78 | loss 2.04631642 |\n",
      "| Epoch  48 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  7.83 | loss 2.04202634 |\n",
      "| Epoch  48 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.89 | loss 2.00001013 |\n",
      "| Epoch  48 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  7.91 | loss 2.02923863 |\n",
      "| Epoch  48 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  7.68 | loss 1.99353835 |\n",
      "| Epoch  48 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.32 | loss 2.02933169 |\n",
      "| Epoch  49 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  8.01 | loss 2.01038039 |\n",
      "| Epoch  49 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  8.15 | loss 2.05328832 |\n",
      "| Epoch  49 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.01 | loss 2.04286928 |\n",
      "| Epoch  49 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  7.53 | loss 2.10072662 |\n",
      "| Epoch  49 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  8.10 | loss 1.96982006 |\n",
      "| Epoch  49 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.41 | loss 1.99110782 |\n",
      "| Epoch  49 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  8.44 | loss 1.98039773 |\n",
      "| Epoch  50 |   128/  856 batches |   512/ 3422 samples | lr 0.00010 | ms/batch  8.32 | loss 2.05943710 |\n",
      "| Epoch  50 |   256/  856 batches |  1024/ 3422 samples | lr 0.00010 | ms/batch  7.42 | loss 1.98876533 |\n",
      "| Epoch  50 |   384/  856 batches |  1536/ 3422 samples | lr 0.00010 | ms/batch  8.30 | loss 1.99831622 |\n",
      "| Epoch  50 |   512/  856 batches |  2048/ 3422 samples | lr 0.00010 | ms/batch  8.63 | loss 2.03028287 |\n",
      "| Epoch  50 |   640/  856 batches |  2560/ 3422 samples | lr 0.00010 | ms/batch  8.37 | loss 2.04387270 |\n",
      "| Epoch  50 |   768/  856 batches |  3072/ 3422 samples | lr 0.00010 | ms/batch  8.34 | loss 2.01634534 |\n",
      "| Epoch  50 |   856/  856 batches |  3422/ 3422 samples | lr 0.00010 | ms/batch  7.82 | loss 1.95175662 |\n",
      "\n",
      " Test statistics \n",
      "\n",
      "| Average Loss 1.91030 | Average Probability Density 0.07282 | Average MAE on mean 3.30110 |\n",
      "| Average mean 0.37358 | Average absolute value of mean 1.21467 | Average variance 20.52281 |\n",
      "\n",
      "| Singular Loss 1.82139 | Singular Probability Density 0.07162 | Singular MAE on mean 2.63986 |\n",
      "\n",
      "Model saved to path: outputs/TESTING/Future_Forecast/GLD_20_day_1/Future_Forecast.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run ./app/ComNet_Train.py \\\n",
    "--inputs_file_name '../Data/Input/selected_1/input_data.pkl' \\\n",
    "--targets_file_name '../Data/Input/Future_Forecast/input_target_GLD_20_day.pkl' \\\n",
    "--save_dir 'outputs/TESTING' --name 'Future_Forecast' --version 'GLD_20_day_1' --gpu_accel \\\n",
    "--model_config '{\"model_args\": {\"history_length\": 100, \"num_inputs\": 30, \"num_channels\": [32,16,8], \"activation\": \"gelu\", \"kernel_size\": 10, \"dropout\": 0.5}}' \\\n",
    "--optimizer 'SGD' --lr '1e-4' --weight_decay '0.001' --sample_noise '0.05' \\\n",
    "--batch_size '4' --log_interval '128' --epochs '50' --eval_interval '5' \\\n",
    "--weight_hist --print_singular \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46e192c-e96d-458e-b577-78cafb1b4d66",
   "metadata": {},
   "source": [
    "# Scheduler arg templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e353cec-60d5-43ac-ae83-5d38ded6acfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_config template for plateau\n",
    "--lr_config '{\"sched_args\": {\"method\": \"plateau\", \"factor\": \"1/np.sqrt(10)\", \"patience\": 5, \"threshold\": 0.1}}' \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ab0fb6-82a2-4e5d-9799-19c71550e6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_config template for cosine_warm\n",
    "--lr_config '{\"sched_args\": {\"method\": \"cosine_warm\", \"t_0\": 10, \"t_mult\": 1}}' \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38043018-4515-4367-8095-01d6128ed052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_config template for one_cycle\n",
    "--lr_config '{\"sched_args\": {\"method\": \"one_cycle\", \"max_lr\": 1e-3, \"three_phase\": true}}' \\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b657ecb-d8b8-4d5f-962f-eac4c56693c2",
   "metadata": {},
   "source": [
    "### LR_find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9e01a8a-4675-46a4-af6a-d196576ee1a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple MPS Framework for GPU acceleration with 1 local device/s \n",
      "\n",
      "LR finder begins... \n",
      "\n",
      "Run number:  1\n",
      "length of loss array in this run:  3045\n",
      "lr with the minimum loss for this run:  -5.995087719298246\n",
      "\n",
      "Run number:  2\n",
      "length of loss array in this run:  3045\n",
      "lr with the minimum loss for this run:  -3.717426900584832\n",
      "\n",
      "Run number:  3\n",
      "length of loss array in this run:  3045\n",
      "lr with the minimum loss for this run:  -2.453333333333391\n",
      "\n",
      "Run number:  4\n",
      "length of loss array in this run:  3045\n",
      "lr with the minimum loss for this run:  -5.96561403508772\n",
      "\n",
      "Run number:  5\n",
      "length of loss array in this run:  3045\n",
      "lr with the minimum loss for this run:  -2.45988304093573\n",
      "\n",
      "Run number:  6\n",
      "length of loss array in this run:  3045\n",
      "lr with the minimum loss for this run:  -6.0\n",
      "\n",
      "Run number:  7\n",
      "length of loss array in this run:  3045\n",
      "lr with the minimum loss for this run:  -5.990175438596491\n",
      "\n",
      "Run number:  8\n",
      "length of loss array in this run:  2116\n",
      "lr with the minimum loss for this run:  -3.352280701754429\n",
      "\n",
      "Run number:  9\n",
      "length of loss array in this run:  3045\n",
      "lr with the minimum loss for this run:  -3.7992982456140707\n",
      "\n",
      "Run number:  10\n",
      "length of loss array in this run:  3045\n",
      "lr with the minimum loss for this run:  -3.3932163742690484\n",
      "\n",
      "\n",
      "Overall result: \n",
      "Log lr with the minimum loss in aggregate:  -3.791111111111147\n",
      "This equates to a learning rate of: 1.618e-04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run ./app/ComNet_lrfind.py \\\n",
    "--inputs_file_name '../Data/Input/Basic/input_data.pkl' \\\n",
    "--targets_file_name '../Data/Input/Basic/input_target.pkl' \\\n",
    "--save_dir 'outputs/TESTING' --name 'lrfind_build' --version 'batch_4' --gpu_accel \\\n",
    "--model_config '{\"model_args\": {\"history_length\": 100, \"num_inputs\": 81, \"num_channels\": [16,8], \"activation\": \"gelu\", \"kernel_size\": 3, \"dropout\": 0.5}}' \\\n",
    "--optimizer 'SGD' --lr_init '1e-6' --lr_max '1e1' --weight_decay '0.1' \\\n",
    "--batch_size '4' --beta '0.99' --epochs '5' --num_runs '10'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
