{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba50d759",
   "metadata": {},
   "source": [
    "# TCN Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca74ef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.nn.utils import weight_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b38061",
   "metadata": {},
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51950bd0",
   "metadata": {},
   "source": [
    "### Transposing Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f0505bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10],\n",
       "       [11, 12, 13, 14, 15]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([\n",
    "    [1,2,3,4,5],\n",
    "    [6,7,8,9,10],\n",
    "    [11,12,13,14,15]\n",
    "])\n",
    "    \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89581ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  6, 11],\n",
       "       [ 2,  7, 12],\n",
       "       [ 3,  8, 13],\n",
       "       [ 4,  9, 14],\n",
       "       [ 5, 10, 15]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function is used to create time series when the input is\n",
    "# an array of vectors with each corresponding to one timestep.\n",
    "\n",
    "y = x.transpose(-1,-2)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0a3693",
   "metadata": {},
   "source": [
    "### Adaptive Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8937ea21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.6738,  0.1459, -1.9430,  0.5504, -0.9537,  0.2500, -1.2200,\n",
      "          -0.5923],\n",
      "         [ 0.0101, -1.0994, -2.0720, -0.9472,  1.0134, -1.0683,  2.1990,\n",
      "           1.4274],\n",
      "         [ 0.1794, -0.9806,  3.2110,  1.0176, -1.8194, -0.1435,  0.2970,\n",
      "          -1.5161],\n",
      "         [ 0.5059, -1.4812, -0.6248,  0.3844, -0.2665, -1.2313, -0.1889,\n",
      "           1.5237],\n",
      "         [ 1.1059,  0.6436, -0.2907,  1.0372,  1.1967,  1.0620,  1.3572,\n",
      "          -1.9616],\n",
      "         [ 0.5541, -1.0523,  0.3244,  1.3744, -1.2967, -0.8231,  1.6053,\n",
      "           2.8394],\n",
      "         [ 0.2907,  1.4062, -0.2424, -0.4257,  0.2236,  0.1361, -1.0883,\n",
      "          -2.3522],\n",
      "         [ 0.4982, -1.7123, -0.8709, -1.0169,  0.6790, -0.4194, -1.7055,\n",
      "          -3.0911],\n",
      "         [-0.1077, -0.2264,  0.0804,  0.5738, -0.6949,  0.5811, -0.5590,\n",
      "           0.2913],\n",
      "         [ 0.8036,  0.3029,  0.1105, -1.6600, -0.9068, -0.8718,  2.2352,\n",
      "           0.6868]]])\n",
      "tensor([[[0.5504, 0.2500],\n",
      "         [0.0101, 2.1990],\n",
      "         [3.2110, 0.2970],\n",
      "         [0.5059, 1.5237],\n",
      "         [1.1059, 1.3572],\n",
      "         [1.3744, 2.8394],\n",
      "         [1.4062, 0.2236],\n",
      "         [0.4982, 0.6790],\n",
      "         [0.5738, 0.5811],\n",
      "         [0.8036, 2.2352]]])\n",
      "torch.Size([1, 10, 2])\n"
     ]
    }
   ],
   "source": [
    "# Adaptive max pooling is used to reduce the dimensionality of the input\n",
    "# The input is split up into n chunks and the maximum entry in each chunk is retained in the output.\n",
    "\n",
    "n = 2\n",
    "m = nn.AdaptiveMaxPool1d(n)\n",
    "input = torch.randn(1, 10, 8)\n",
    "\n",
    "output = m(input)\n",
    "print(input)\n",
    "print(output)\n",
    "\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "916bdf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.8550, -0.3290, -0.5676, -0.7550,  0.8608,  0.5145, -0.4325,\n",
      "           0.1836],\n",
      "         [-1.1026, -1.4264, -0.7803, -1.3181, -0.3238,  0.6133, -0.1001,\n",
      "          -0.2332],\n",
      "         [ 1.0694, -0.9311, -0.5157,  2.1294, -0.4560, -1.7986, -0.4551,\n",
      "          -0.1024],\n",
      "         [-0.8484, -1.1227, -0.2158, -0.1050,  1.4975,  0.2288, -0.2153,\n",
      "           0.4944],\n",
      "         [-0.3289, -1.3043, -0.9896, -0.0110,  0.7123, -0.3579,  1.5000,\n",
      "          -1.8310],\n",
      "         [-1.7235,  1.2236, -0.0754, -0.0234, -0.0733,  1.0821, -0.0297,\n",
      "           0.1330],\n",
      "         [-2.1905,  1.4125, -0.9819,  0.1323,  1.1706, -0.1566,  1.2730,\n",
      "           1.8208],\n",
      "         [-0.2982,  0.3976,  0.9994,  0.6967,  0.5351,  0.5108, -1.6749,\n",
      "           0.5342],\n",
      "         [-0.7169,  0.1687,  0.7361,  0.7410, -1.2018, -1.7414, -0.4973,\n",
      "          -1.8722],\n",
      "         [ 0.3125,  0.1573,  0.0790,  1.2682,  0.3986, -1.1823, -1.4031,\n",
      "           1.3306]]])\n",
      "tensor([[[0.8608],\n",
      "         [0.6133],\n",
      "         [2.1294],\n",
      "         [1.4975],\n",
      "         [1.5000],\n",
      "         [1.2236],\n",
      "         [1.8208],\n",
      "         [0.9994],\n",
      "         [0.7410],\n",
      "         [1.3306]]])\n",
      "tensor([[0.8608, 0.6133, 2.1294, 1.4975, 1.5000, 1.2236, 1.8208, 0.9994, 0.7410,\n",
      "         1.3306]])\n"
     ]
    }
   ],
   "source": [
    "# Squeeze(-1) simply removes the last i.e. the lowest dimentsion of the tensor after max pooling\n",
    "\n",
    "n = 1\n",
    "m = nn.AdaptiveMaxPool1d(n)\n",
    "input = torch.randn(1, 10, 8)\n",
    "\n",
    "output = m(input)\n",
    "print(input)\n",
    "print(output)\n",
    "\n",
    "print(output.squeeze(-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e316ab",
   "metadata": {},
   "source": [
    "## Testing Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c61e8c",
   "metadata": {},
   "source": [
    "### Chomp1d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a57ee505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.3662, -0.4530,  0.9133, -1.8705,  1.0084, -0.1480, -0.2611,\n",
      "          -0.3330,  0.5459,  0.4545],\n",
      "         [ 0.1157,  0.8037, -0.3166,  0.3968,  0.5129, -0.4063,  0.0884,\n",
      "          -1.2360,  0.1519,  0.0514],\n",
      "         [ 0.5537, -0.3588,  0.7492, -1.3030, -0.2966, -0.5220, -1.1743,\n",
      "          -0.3231, -0.9828,  0.4961],\n",
      "         [-0.5783, -0.6165,  0.2878, -1.7264,  0.2994,  0.9694,  0.5157,\n",
      "          -0.1501, -0.2851, -0.9014],\n",
      "         [ 0.1430, -0.5479,  0.0938, -1.5846,  0.4975, -1.0417, -0.4890,\n",
      "          -0.3011, -1.9909, -0.2687],\n",
      "         [ 1.9303, -0.2923, -1.8888,  0.1315, -0.5930, -1.5550, -0.4376,\n",
      "           0.4946, -1.4731,  0.0102],\n",
      "         [ 0.5294,  0.2273, -0.2997,  0.6690,  0.5647, -0.5846, -0.9580,\n",
      "          -1.0514,  3.0484,  0.3631],\n",
      "         [ 0.4330,  0.2814,  1.4383,  1.9686, -1.6647,  0.6168, -1.3011,\n",
      "          -0.1112,  0.1016,  2.3426],\n",
      "         [-0.1750, -0.0091, -0.9142, -0.0672,  0.4026,  0.3471, -0.8517,\n",
      "          -0.8561,  1.0335,  0.0267],\n",
      "         [-0.8945,  0.3597,  0.1739,  0.2205,  0.6280, -0.3659,  0.5762,\n",
      "          -1.1684,  1.5071,  1.0807]]])\n",
      "tensor([[[ 0.3662, -0.4530,  0.9133, -1.8705,  1.0084, -0.1480, -0.2611],\n",
      "         [ 0.1157,  0.8037, -0.3166,  0.3968,  0.5129, -0.4063,  0.0884],\n",
      "         [ 0.5537, -0.3588,  0.7492, -1.3030, -0.2966, -0.5220, -1.1743],\n",
      "         [-0.5783, -0.6165,  0.2878, -1.7264,  0.2994,  0.9694,  0.5157],\n",
      "         [ 0.1430, -0.5479,  0.0938, -1.5846,  0.4975, -1.0417, -0.4890],\n",
      "         [ 1.9303, -0.2923, -1.8888,  0.1315, -0.5930, -1.5550, -0.4376],\n",
      "         [ 0.5294,  0.2273, -0.2997,  0.6690,  0.5647, -0.5846, -0.9580],\n",
      "         [ 0.4330,  0.2814,  1.4383,  1.9686, -1.6647,  0.6168, -1.3011],\n",
      "         [-0.1750, -0.0091, -0.9142, -0.0672,  0.4026,  0.3471, -0.8517],\n",
      "         [-0.8945,  0.3597,  0.1739,  0.2205,  0.6280, -0.3659,  0.5762]]])\n",
      "tensor([[[ 0.3662, -0.4530,  0.9133, -1.8705,  1.0084],\n",
      "         [ 0.1157,  0.8037, -0.3166,  0.3968,  0.5129],\n",
      "         [ 0.5537, -0.3588,  0.7492, -1.3030, -0.2966],\n",
      "         [-0.5783, -0.6165,  0.2878, -1.7264,  0.2994],\n",
      "         [ 0.1430, -0.5479,  0.0938, -1.5846,  0.4975],\n",
      "         [ 1.9303, -0.2923, -1.8888,  0.1315, -0.5930],\n",
      "         [ 0.5294,  0.2273, -0.2997,  0.6690,  0.5647],\n",
      "         [ 0.4330,  0.2814,  1.4383,  1.9686, -1.6647],\n",
      "         [-0.1750, -0.0091, -0.9142, -0.0672,  0.4026],\n",
      "         [-0.8945,  0.3597,  0.1739,  0.2205,  0.6280]]])\n",
      "tensor([[[ 0.3662, -0.4530,  0.9133],\n",
      "         [ 0.1157,  0.8037, -0.3166],\n",
      "         [ 0.5537, -0.3588,  0.7492],\n",
      "         [-0.5783, -0.6165,  0.2878],\n",
      "         [ 0.1430, -0.5479,  0.0938],\n",
      "         [ 1.9303, -0.2923, -1.8888],\n",
      "         [ 0.5294,  0.2273, -0.2997],\n",
      "         [ 0.4330,  0.2814,  1.4383],\n",
      "         [-0.1750, -0.0091, -0.9142],\n",
      "         [-0.8945,  0.3597,  0.1739]]])\n"
     ]
    }
   ],
   "source": [
    "# The chomp class simply removes the last chomp_size entries from each channel.\n",
    "# This is only necessary to remove the padding at the end of the layer.\n",
    "\n",
    "x = torch.randn(1, 10, 10)\n",
    "\n",
    "print(x)\n",
    "print(x[:, :, :-3])\n",
    "print(x[:, :, :-5])\n",
    "print(x[:, :, :-7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29abea15",
   "metadata": {},
   "source": [
    "### Conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4df4118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets apply a 1d conv to some test data to figure out how it works\n",
    "\n",
    "class TestConv(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        \n",
    "        super(TestConv, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(n_inputs, n_outputs, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1)\n",
    "        \n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a4331a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[ 0.0007,  0.0065, -0.0023],\n",
      "         [ 0.0245, -0.0144,  0.0042],\n",
      "         [ 0.0037,  0.0118, -0.0015],\n",
      "         [-0.0019, -0.0157, -0.0021],\n",
      "         [ 0.0118, -0.0229, -0.0047],\n",
      "         [ 0.0112, -0.0127, -0.0013],\n",
      "         [ 0.0061,  0.0007,  0.0066],\n",
      "         [ 0.0020, -0.0095,  0.0263],\n",
      "         [ 0.0060,  0.0053,  0.0217],\n",
      "         [-0.0015,  0.0028,  0.0194]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1789], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Lets keep it simple to start and have only one output channel with no dilation\n",
    "\n",
    "x = torch.randn(1, 10, 10)\n",
    "\n",
    "TestBlock = TestConv(n_inputs=10, n_outputs=1, kernel_size=3, stride=1, dilation=1, padding=1, dropout=0.2)\n",
    "print(TestBlock.conv1.weight)\n",
    "print(TestBlock.conv1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a0bac6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 7.3331e-01,  1.9775e+00,  3.0415e-01,  7.1883e-01, -2.1124e-01,\n",
      "          -8.8180e-02, -6.1135e-01,  6.5577e-01,  1.2377e+00, -2.5969e-01],\n",
      "         [-5.0379e-02,  1.4218e+00,  3.0685e-01, -1.3138e-01, -9.0272e-01,\n",
      "          -1.1392e+00,  6.6706e-01,  2.3474e-01, -1.3778e+00,  5.0836e-01],\n",
      "         [ 8.0168e-01,  8.5237e-02, -2.7927e-01,  5.0594e-01,  9.0535e-01,\n",
      "           4.9328e-01,  2.3420e-01, -1.2688e+00, -7.2514e-01,  2.0129e+00],\n",
      "         [-5.9111e-01, -4.3180e-01, -1.0639e+00,  2.1870e-01,  1.1672e+00,\n",
      "           5.3729e-01, -5.5616e-01,  6.1319e-01, -5.6282e-01,  6.1455e-01],\n",
      "         [ 1.6820e+00,  1.5387e+00, -1.6835e-01, -1.7795e-01, -1.2743e+00,\n",
      "           3.6689e-01,  1.0651e-01,  8.3296e-01, -2.2056e-01,  7.3387e-01],\n",
      "         [ 7.6575e-01,  1.5882e+00, -7.9935e-01, -1.8805e+00, -4.3445e-02,\n",
      "          -5.1776e-01, -1.4095e-01,  6.0506e-01, -5.2607e-01, -3.0991e-01],\n",
      "         [-6.1063e-01,  1.4187e+00, -1.3465e+00,  8.7434e-01, -1.0748e+00,\n",
      "          -1.1487e-01, -1.7511e-01,  9.5772e-02,  3.7633e-01, -1.9851e+00],\n",
      "         [ 1.6023e+00, -2.4014e-01, -9.6438e-01,  1.1948e+00,  7.1364e-01,\n",
      "           4.7579e-01,  4.3664e-01, -1.1971e-03,  1.8404e+00, -9.5109e-01],\n",
      "         [ 5.9962e-01, -1.5058e+00,  8.3397e-01,  4.3117e-01,  5.5904e-01,\n",
      "           2.0125e+00, -2.3705e-02,  3.4206e-01,  1.4642e-01, -1.0608e+00],\n",
      "         [ 8.4226e-02,  5.3753e-01, -3.3153e-01, -5.6331e-01, -6.8182e-01,\n",
      "          -1.1381e+00,  1.7558e+00, -1.1072e+00,  3.0726e-01,  4.5458e-03]]])\n",
      "tensor([[[-0.2415, -0.2203, -0.0351, -0.1490, -0.1390, -0.1534, -0.2137,\n",
      "          -0.1607, -0.1991, -0.2213]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Here are the input and output\n",
    "\n",
    "print(x)\n",
    "print(TestBlock(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "371ac006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([-0.2203])\n"
     ]
    }
   ],
   "source": [
    "# Theoretically the outputs are a sum of some inputs times the weights\n",
    "# Here I try to see which inputs are linked to which outputs.\n",
    "\n",
    "total = 0\n",
    "pos = 0\n",
    "\n",
    "for j in range(0,10):\n",
    "    for i in range(0,3):\n",
    "        \n",
    "        #print(x[0,j,pos+i])\n",
    "        total += x[0,j,pos+i]*TestBlock.conv1.weight.data[0,j,i]\n",
    "\n",
    "print()\n",
    "print(total+TestBlock.conv1.bias.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa5cc55",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "587016b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[-0.0145, -0.0032, -0.0024],\n",
      "         [ 0.0120, -0.0060, -0.0052],\n",
      "         [ 0.0136, -0.0106,  0.0066],\n",
      "         [ 0.0027,  0.0073, -0.0032],\n",
      "         [ 0.0171,  0.0111, -0.0165],\n",
      "         [-0.0176, -0.0067, -0.0045],\n",
      "         [-0.0115,  0.0017, -0.0021],\n",
      "         [ 0.0096, -0.0184, -0.0031],\n",
      "         [ 0.0225, -0.0038,  0.0088],\n",
      "         [-0.0105,  0.0046,  0.0075]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1179], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# In the above if we add padding then the corresponding number of first and last entries\n",
    "# are based on padded values.\n",
    "\n",
    "# If we define our padding as (k-1)d then the first node will always see only the first datapoint.\n",
    "# This ensures a causal connection.\n",
    "\n",
    "ker = 3\n",
    "dil = 1\n",
    "\n",
    "TestBlock2 = TestConv(n_inputs=10, n_outputs=1, kernel_size=ker, stride=1, dilation=dil, padding=(ker-1)*dil, dropout=0.2)\n",
    "print(TestBlock2.conv1.weight)\n",
    "print(TestBlock2.conv1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0d193ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[[0.0946, 0.0300, 0.1850, 0.0602, 0.1594, 0.1434, 0.1472, 0.1506,\n",
      "          0.1457, 0.0904, 0.1002, 0.1646]]], grad_fn=<ConvolutionBackward0>)\n",
      "tensor([0.1850])\n"
     ]
    }
   ],
   "source": [
    "# Here we see that the first output based on the input datapoints comes after \n",
    "# the same number of nodes as the padding.\n",
    "\n",
    "total = 0\n",
    "pos = 0\n",
    "\n",
    "for j in range(0,10):\n",
    "    for i in range(0,3):\n",
    "        \n",
    "        #print(x[0,j,pos+i])\n",
    "        total += x[0,j,pos+i]*TestBlock2.conv1.weight.data[0,j,i]\n",
    "\n",
    "print()\n",
    "print(TestBlock2(x))\n",
    "print(total+TestBlock2.conv1.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bb14f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0946, 0.0300, 0.1850, 0.0602, 0.1594, 0.1434, 0.1472, 0.1506,\n",
      "          0.1457, 0.0904, 0.1002, 0.1646]]], grad_fn=<ConvolutionBackward0>)\n",
      "tensor([[[0.0946, 0.0300, 0.1850, 0.0602, 0.1594, 0.1434, 0.1472, 0.1506,\n",
      "          0.1457, 0.0904]]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# By applying the same filter as the function chomp1d we disregard\n",
    "# a number of nodes at the end of the layer equal to the padding.\n",
    "\n",
    "print(TestBlock2(x))\n",
    "print(TestBlock2(x)[:, :, :-((ker-1)*dil)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc1c7555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, and perhaps preferably, a class can be used to apply single sided padding.\n",
    "# In this way Chomp1d will not be required.\n",
    "\n",
    "class CausalConv1d(nn.Conv1d):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, dilation=1, groups=1, bias=True):\n",
    "\n",
    "        super(CausalConv1d, self).__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride,\n",
    "            padding=0,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=bias)\n",
    "        \n",
    "        self.__padding = (kernel_size - 1) * dilation\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        return super(CausalConv1d, self).forward(F.pad(input, (self.__padding, 0)))\n",
    "    \n",
    "    \n",
    "class TestConv(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, dropout=0.2):\n",
    "        \n",
    "        super(TestConv, self).__init__()\n",
    "        \n",
    "        self.conv1 = CausalConv1d(n_inputs, n_outputs, kernel_size, stride=stride, dilation=dilation)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1)\n",
    "        \n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85d4a126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[-0.0070,  0.0017,  0.0119],\n",
      "         [ 0.0022, -0.0087, -0.0082],\n",
      "         [ 0.0130,  0.0043,  0.0047],\n",
      "         [ 0.0023,  0.0184,  0.0095],\n",
      "         [ 0.0006,  0.0016, -0.0123],\n",
      "         [ 0.0100, -0.0029,  0.0079],\n",
      "         [-0.0185,  0.0037, -0.0012],\n",
      "         [-0.0050,  0.0050, -0.0001],\n",
      "         [ 0.0008, -0.0035,  0.0016],\n",
      "         [ 0.0186,  0.0035,  0.0163]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0650], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Now we should not need to apply padding for the convolution or chomp1d afterwards\n",
    "\n",
    "x = torch.randn(1, 10, 10)\n",
    "\n",
    "TestBlock = TestConv(n_inputs=10, n_outputs=1, kernel_size=3, stride=1, dilation=1, dropout=0.2)\n",
    "print(TestBlock.conv1.weight)\n",
    "print(TestBlock.conv1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4760ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[[0.0853, 0.0617, 0.1216, 0.0573, 0.0288, 0.0154, 0.0635, 0.1616,\n",
      "          0.1304, 0.1122]]], grad_fn=<ConvolutionBackward0>)\n",
      "tensor([0.1122])\n"
     ]
    }
   ],
   "source": [
    "# Now we see that once again the first two nodes of the output are based on padding.\n",
    "# However the last node is now based entirely on the inputs and the length of the layer matches the input.\n",
    "\n",
    "total = 0\n",
    "pos = 7\n",
    "\n",
    "for j in range(0,10):\n",
    "    for i in range(0,3):\n",
    "        \n",
    "        #print(x[0,j,pos+i])\n",
    "        total += x[0,j,pos+i]*TestBlock.conv1.weight.data[0,j,i]\n",
    "\n",
    "print()\n",
    "print(TestBlock(x))\n",
    "print(total+TestBlock.conv1.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29b4221",
   "metadata": {},
   "source": [
    "## Full Temporal Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e35dbf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have used our custom padding function and changed the activation to Leaky ReLU for now.\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, dropout=0.2):\n",
    "        \n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(CausalConv1d(n_inputs, n_outputs, kernel_size, stride=stride, dilation=dilation))\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(CausalConv1d(n_outputs, n_outputs, kernel_size, stride=stride, dilation=dilation))\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.relu2, self.dropout2)\n",
    "        \n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        \n",
    "        self.out_shape= n_outputs\n",
    "        \n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbd3f82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.4150e-03, -2.2201e-03, -1.9480e-03, -1.2050e-03, -2.0838e-03,\n",
      "          -2.8109e-03, -5.4681e-04, -2.2198e-03, -1.7906e-03,  3.2647e-01],\n",
      "         [-1.8582e-03, -1.8292e-03, -1.5116e-03, -1.3464e-03, -1.4731e-03,\n",
      "          -5.0217e-04, -1.4533e-03, -1.5321e-03, -1.4126e-03, -1.1384e-03],\n",
      "         [ 1.7094e-01,  1.7947e-01,  9.2855e-02,  1.0368e-01, -1.1050e-04,\n",
      "           2.2344e-01,  2.0613e-01, -5.2247e-04, -3.5436e-04,  8.3818e-01],\n",
      "         [-1.1638e-03, -1.5325e-03, -1.6374e-03, -7.4738e-04, -3.0139e-03,\n",
      "          -2.1216e-03,  1.4400e-01,  1.1600e-01, -2.7609e-03, -1.9362e-03],\n",
      "         [ 2.9261e-01,  2.8148e-01,  2.3685e-01,  2.7892e-01,  2.8824e-01,\n",
      "           1.9851e-01,  3.6106e-01,  5.7606e-01,  2.7030e-01,  2.5556e-01]]],\n",
      "       grad_fn=<LeakyReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# This block seems to work just fine\n",
    "\n",
    "x = torch.randn(1, 10, 10)\n",
    "\n",
    "TestBlock = TemporalBlock(n_inputs=10, n_outputs=5, kernel_size=5, stride=1, dilation=1, dropout=0.2)\n",
    "\n",
    "print(TestBlock(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d7385f",
   "metadata": {},
   "source": [
    "## Testing Full Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dffd3e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        \n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        \n",
    "        self.layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        \n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            self.layers += [TemporalBlock(in_channels, out_channels, kernel_size,\n",
    "                                     stride=1, dilation=dilation_size, dropout=dropout)]\n",
    "        \n",
    "        self.out_shape = self.layers[-1].out_shape\n",
    "        self.network = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fcb725f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.8211,  0.8633,  0.7954,  1.0118,  0.9933, -0.2309,  0.8287,\n",
      "          -0.1591, -2.1312,  2.2352],\n",
      "         [ 0.0847,  0.0975, -0.7539,  1.6902, -1.4064, -0.0913, -1.1369,\n",
      "          -0.1919, -0.1626, -0.9789],\n",
      "         [ 0.1559,  0.5798, -1.8434,  0.1558, -0.0197,  1.5330, -1.6641,\n",
      "           0.8156,  0.9160,  0.2828],\n",
      "         [-0.9291, -1.5002,  0.2783,  0.1893,  0.7349, -1.7096,  0.9961,\n",
      "           0.4132,  0.8228,  0.4827],\n",
      "         [ 3.1243, -1.4045,  1.1466,  0.4907,  1.2401,  0.9644, -0.3407,\n",
      "           0.8001, -0.0688, -0.3414],\n",
      "         [-0.2107, -0.8109,  1.0384, -1.2542,  0.1058,  0.5608,  0.3836,\n",
      "           0.1921, -0.6354, -0.5298]]])\n",
      "tensor([[[0.5795, 0.5785, 0.5435, 0.1827, 0.5482, 0.5436, 0.5465, 0.5481,\n",
      "          0.1840, 0.1839]]], grad_fn=<LeakyReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Testing TempConvNet\n",
    "\n",
    "x = torch.randn(1, 6, 10)\n",
    "\n",
    "TestNet = TemporalConvNet(num_inputs=6, num_channels=[5,10,5,1], kernel_size=3, dropout=0.2)\n",
    "\n",
    "print(x)\n",
    "print(TestNet(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c87f7a",
   "metadata": {},
   "source": [
    "# TCN Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "773cb253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.4862e+00,  1.3014e+00,  1.4611e+00, -8.1100e-01, -4.2103e-01,\n",
       "           2.3076e+00, -6.1092e-01, -1.8902e+00, -6.6616e-01,  1.1922e+00],\n",
       "         [-5.6652e-02,  4.5527e-01,  6.2742e-01,  4.1564e-01,  3.9542e-01,\n",
       "          -1.5785e-01, -3.0933e-01,  5.1140e-01,  2.5879e-01, -1.2419e+00],\n",
       "         [-3.4514e-01,  1.4932e+00,  1.5529e-01,  4.7902e-01,  3.1193e-01,\n",
       "          -7.4366e-01, -6.3157e-01, -1.2738e+00, -1.0162e-01, -1.0890e+00],\n",
       "         [-4.8824e-01, -5.8031e-01, -8.4179e-01,  9.7163e-02, -9.7490e-01,\n",
       "          -3.7526e-01, -1.0742e+00,  9.3186e-02,  1.2080e+00,  1.8556e+00],\n",
       "         [-1.1773e+00,  1.2767e+00,  2.1428e+00, -1.3469e+00,  2.7301e-01,\n",
       "           5.8773e-01,  1.4812e+00,  1.5616e+00,  1.7440e-01, -4.3413e-01],\n",
       "         [-7.0214e-01,  1.6590e+00,  7.9579e-01, -5.3867e-01, -7.1562e-01,\n",
       "          -7.9563e-01,  5.6138e-02, -2.6339e-01,  8.5440e-01,  1.7991e+00]],\n",
       "\n",
       "        [[ 5.7744e-02, -6.3469e-01, -1.5595e-01,  8.4911e-01, -2.6266e+00,\n",
       "           1.6591e+00,  1.2750e+00,  9.1528e-01,  1.2456e+00, -1.5181e-01],\n",
       "         [ 1.4934e+00,  1.1864e+00, -1.9060e-01, -1.0944e+00, -9.2310e-01,\n",
       "          -3.7669e-02, -7.8851e-01, -2.1220e+00, -1.2533e+00, -3.9010e-02],\n",
       "         [-9.8999e-01, -1.6857e-01, -2.8834e+00, -3.4914e-02,  1.5078e+00,\n",
       "           3.6358e-01,  2.9737e-01, -2.6527e+00,  7.3706e-01, -5.6915e-01],\n",
       "         [-4.5057e-01, -1.0558e+00, -4.0023e-01,  8.5594e-02, -5.0800e-01,\n",
       "           4.9516e-02,  1.8089e+00, -7.7271e-02, -1.9050e-01, -2.1415e+00],\n",
       "         [ 5.2328e-01,  1.7699e+00, -2.8524e-01,  1.0738e+00, -1.3109e+00,\n",
       "          -7.7515e-01, -1.3510e+00,  1.1061e+00,  1.5617e-01,  6.7063e-01],\n",
       "         [-1.5804e+00,  9.6753e-01,  1.5471e-01, -6.1303e-01, -1.1619e+00,\n",
       "          -3.2786e+00,  7.5866e-01, -1.2694e+00,  6.1555e-01, -9.1986e-03]],\n",
       "\n",
       "        [[-1.1983e+00,  1.4076e+00, -2.0146e+00,  1.7594e-01, -1.6431e+00,\n",
       "          -6.2471e-01,  1.4311e+00, -4.3536e-01,  3.1325e-01, -1.1558e+00],\n",
       "         [-7.3859e-01,  3.1931e-01,  2.7707e-01,  9.4815e-01, -1.4856e-01,\n",
       "           1.0565e+00,  1.2296e+00,  3.3698e-03, -2.0501e-01,  1.2713e+00],\n",
       "         [ 6.3326e-03,  4.2627e-01, -2.6115e-01,  1.3075e-01, -1.8042e+00,\n",
       "           7.5072e-01, -9.6941e-01, -2.8347e-01,  1.5919e+00, -7.6119e-01],\n",
       "         [-3.6352e-02, -3.3443e-01, -6.9038e-01,  4.5897e-02,  1.0442e+00,\n",
       "           8.7269e-01,  2.0340e+00, -2.0626e-01,  1.5512e+00, -7.5977e-01],\n",
       "         [-1.0720e-01,  7.1465e-01,  7.7062e-03, -8.6058e-01,  3.1287e-01,\n",
       "          -9.0636e-01, -1.2319e+00, -1.2595e-01,  5.5454e-01, -3.8081e-01],\n",
       "         [ 2.1869e+00, -2.0221e+00, -1.0424e+00, -4.5874e-01, -7.6323e-01,\n",
       "          -7.5702e-01,  3.3864e+00, -1.5941e+00,  2.1125e-02, -4.1270e-02]],\n",
       "\n",
       "        [[-4.9903e-01, -1.3735e+00, -1.0882e+00,  1.0013e+00, -2.5737e-01,\n",
       "           2.0631e-01,  5.7752e-01,  2.2787e-01,  3.1963e-01,  2.5892e+00],\n",
       "         [ 5.2235e-02, -5.3252e-01,  2.9473e+00, -7.3513e-01, -7.1227e-01,\n",
       "           1.5454e+00, -6.5967e-01,  9.3367e-01, -4.9717e-01,  3.0282e-01],\n",
       "         [-1.2679e+00,  2.5239e-01, -7.8883e-01, -5.1101e-01, -6.2458e-01,\n",
       "          -1.6398e+00, -1.2071e+00, -7.6944e-01, -1.5915e-01, -6.7536e-01],\n",
       "         [-6.8983e-01, -1.6021e+00, -1.3971e-01,  6.4545e-01,  4.4605e-01,\n",
       "           1.2401e+00, -2.2107e-01,  1.8172e+00, -1.5580e+00,  1.4550e+00],\n",
       "         [ 7.6240e-01, -9.1642e-01, -7.1298e-01, -1.7145e+00, -1.7676e+00,\n",
       "          -3.6692e+00,  1.8072e+00,  3.1037e-01, -1.4643e+00,  1.2896e+00],\n",
       "         [-2.5342e-01,  6.8143e-01,  2.9504e-01,  4.0268e-01,  3.4636e-01,\n",
       "           5.7952e-01,  5.7859e-01,  3.5322e-01,  2.4339e-01, -3.5441e-01]],\n",
       "\n",
       "        [[-7.6389e-01, -2.5368e-01, -1.2118e+00, -8.2367e-02,  4.1870e-01,\n",
       "          -1.6045e-01, -1.1250e+00,  1.2288e-01,  1.2081e+00, -2.1903e+00],\n",
       "         [ 1.4541e+00,  2.0408e+00, -1.1761e+00, -1.0170e+00, -6.8320e-01,\n",
       "          -1.2483e+00, -3.2941e-01, -7.8063e-01,  1.0073e+00,  6.2612e-03],\n",
       "         [ 1.1287e+00,  7.7752e-01,  3.0548e-01, -5.6130e-01, -4.5097e-01,\n",
       "           9.3067e-01, -1.6367e-01, -6.4627e-01,  3.6004e-01, -5.9265e-01],\n",
       "         [ 1.0571e-02, -1.2795e+00, -4.6020e-01,  1.0573e-01,  6.9304e-01,\n",
       "           5.6292e-02,  1.4043e+00, -1.6280e+00,  2.1469e+00,  3.6012e-02],\n",
       "         [-6.8058e-01, -1.5959e+00, -6.8235e-01,  6.1613e-01, -3.3320e-01,\n",
       "           2.3694e-01,  2.4479e-01, -1.6658e+00, -8.1195e-01, -3.5152e-02],\n",
       "         [ 1.2107e+00,  9.9782e-01,  8.8355e-01,  2.3868e-01,  1.6949e+00,\n",
       "          -2.4983e-01,  6.7343e-01, -1.9552e-01, -7.4532e-01,  1.3912e+00]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a batch of 5 datapoints\n",
    "# Each of which represents a dataseries of 6 channels for 10 timesteps\n",
    "\n",
    "x = torch.randn(5, 6, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85962b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCN(nn.Module):\n",
    "    \n",
    "    def __init__(self, history_length, num_inputs, num_channels, kernel_size=3, dropout=0.2):\n",
    "        \n",
    "        super(TCN, self).__init__()\n",
    "        \n",
    "        self.tcn = TemporalConvNet(num_inputs, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
    "        self.linear = nn.Linear(self.tcn.out_shape*history_length, 2)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \n",
    "        self.linear.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        y = self.tcn(x)\n",
    "        \n",
    "        return self.linear(y.flatten(-2,-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb38b356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4484,  0.2694, -0.1080,  0.5048,  0.2528, -0.4251,  0.4190,\n",
      "           1.0363,  0.3881,  0.8975],\n",
      "         [-0.2410,  0.5322, -0.5830,  0.2108, -0.6551, -0.7796,  0.5090,\n",
      "           0.8757, -0.2601, -0.9079],\n",
      "         [ 0.1467, -1.0168,  1.7070, -1.0367, -0.9253,  0.9366,  1.1271,\n",
      "           1.3953,  0.5355,  0.4172],\n",
      "         [-0.3138, -1.5123,  1.0982, -0.5915,  0.1300, -1.1624,  0.8005,\n",
      "          -0.7134,  1.0289, -0.4027],\n",
      "         [-0.3494,  0.1402, -0.4686,  0.1226,  0.3346,  1.5586,  0.2866,\n",
      "           0.4353, -0.5142, -2.1595],\n",
      "         [ 0.5346,  0.2737,  1.2471, -1.0877,  0.3483,  0.0458, -0.5418,\n",
      "           0.2794,  0.9913, -0.5336]],\n",
      "\n",
      "        [[-1.2928,  0.2680,  0.3462, -0.9636,  0.8960, -0.0047,  1.4130,\n",
      "          -1.1548, -0.5173,  0.1223],\n",
      "         [ 0.2855,  1.2524,  0.4575,  1.1822, -1.0817,  0.1718,  0.8343,\n",
      "           0.3039,  0.4843,  1.0413],\n",
      "         [ 0.1196, -2.5525, -1.5409,  0.6379,  0.1822, -0.1177,  0.0065,\n",
      "           0.2777, -0.1573,  0.3910],\n",
      "         [-1.1147,  1.2142,  1.5740,  1.5064,  0.3217, -2.1205, -2.1513,\n",
      "          -3.9100,  0.6290,  0.0808],\n",
      "         [ 0.9844, -0.9015, -1.6015,  0.8665,  0.4890,  1.2041,  0.2282,\n",
      "          -0.5530,  0.9466,  0.3292],\n",
      "         [ 0.0187, -0.5226,  0.0260, -0.6913,  1.0253, -1.0492, -0.8885,\n",
      "           1.3264,  0.9724, -0.6153]],\n",
      "\n",
      "        [[-1.0284, -0.1158, -0.2271,  1.5395,  1.1216,  0.7858, -0.0799,\n",
      "           0.2945,  0.6294,  0.4607],\n",
      "         [ 0.4273,  0.5598, -0.0370,  0.9771, -1.3576,  0.3850, -0.6835,\n",
      "          -1.7915,  0.7600, -0.0811],\n",
      "         [-1.1255,  2.1384,  0.3352, -0.3656,  0.5426, -2.8456,  1.8086,\n",
      "          -1.5673,  0.1777,  1.1790],\n",
      "         [-0.9034, -1.4340, -0.0205,  0.3010,  0.5688, -0.2929, -2.5692,\n",
      "           0.2634, -0.1460,  0.4909],\n",
      "         [ 0.7945, -1.8644,  1.4881,  1.1458,  0.2483, -1.0966,  1.4739,\n",
      "           0.4171,  0.5369, -0.4269],\n",
      "         [ 0.8225,  0.0090,  0.0393, -0.4358,  0.3404,  0.3382,  0.8525,\n",
      "           1.0625,  0.6518, -1.2666]],\n",
      "\n",
      "        [[ 0.7421,  0.4729,  2.2442,  0.9131, -0.9772,  0.5338, -1.2285,\n",
      "           1.5737,  0.1566, -1.9425],\n",
      "         [ 0.7577, -2.5813,  1.1375,  1.5051, -0.4906, -0.6404, -0.3589,\n",
      "          -0.1999, -0.2559, -1.0639],\n",
      "         [-0.0061,  0.9844, -0.5320, -0.5848,  0.8817, -0.3763,  0.1020,\n",
      "           1.6950, -1.6358,  0.7313],\n",
      "         [ 0.0658,  0.7208,  1.0384, -1.4340, -0.3594, -1.2419, -0.3919,\n",
      "           0.8806,  1.7829, -0.3519],\n",
      "         [-0.3316,  1.1987,  0.4411, -0.1318, -0.4355, -0.9749, -0.4245,\n",
      "           1.7373,  0.0709,  0.9381],\n",
      "         [ 1.0518,  1.0876,  0.1380,  0.2429,  1.1458, -0.0444,  0.6926,\n",
      "          -0.3199, -1.1602, -0.4382]],\n",
      "\n",
      "        [[ 1.1715, -1.2527, -1.9760, -1.2288,  0.3820, -2.8017, -1.6056,\n",
      "           2.3350,  0.2387,  0.9237],\n",
      "         [ 0.7495,  1.0832,  0.0751,  0.0329,  0.7329, -0.2867,  0.6615,\n",
      "          -1.2229, -0.5552,  1.0909],\n",
      "         [-0.0590,  2.1489,  1.2235, -1.1408,  0.0307, -1.8149, -0.6651,\n",
      "          -0.8545, -0.5637, -2.1773],\n",
      "         [ 0.2731, -0.0631, -0.3464,  1.6194,  0.4828, -0.1749, -1.1500,\n",
      "           0.2133, -1.0437, -0.4521],\n",
      "         [ 1.0628, -1.9670, -0.9955, -0.2009,  0.3612, -0.2230, -0.2833,\n",
      "           1.0195, -0.2422, -0.3910],\n",
      "         [ 1.3197,  0.5897,  0.5371, -1.1080, -0.4331,  0.7270, -0.7654,\n",
      "          -0.5284, -0.0309, -0.3352]]])\n",
      "tensor([[0.1486, 0.0982],\n",
      "        [0.1487, 0.1005],\n",
      "        [0.1458, 0.1018],\n",
      "        [0.1489, 0.1008],\n",
      "        [0.1492, 0.0998]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Testing TempConvNet\n",
    "\n",
    "x = torch.randn(5, 6, 10)\n",
    "\n",
    "TestTCN = TCN(history_length=10, num_inputs=6, num_channels=[5,10,5,3], kernel_size=3, dropout=0.2)\n",
    "\n",
    "print(x)\n",
    "print(TestTCN(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080f4686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
